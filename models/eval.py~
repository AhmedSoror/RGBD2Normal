############################
# Evaluate estimated normal
# criterion include:
# mean, median, 11.25, 22.5, 30
# Jin Zeng, 20180821
############################
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

def eval_normal(input, label, mask):
    # bs = 1 for testing
    # input: bs*ch*h*w
    # label: bs*h*w*ch
    # mask: bs*h*w
    bz, ch, h, w = input.size()
    
    # normalization
    input = input.permute(0,2,3,1).contiguous().view(-1,ch)
    input_v = F.normalize(input,p=2)    
    label_v = label.contiguous().view(-1,ch)
    input_v[torch.isnan(input_v)] = 0

    mask_t = mask.view(-1,1)
    mask_t = torch.squeeze(mask_t)

    loss = F.cosine_similarity(input_v, label_v)#compute inner product     
    loss[torch.ge(loss,1)] = 1
    loss[torch.le(loss,-1)] = -1  
    loss_angle = (180/np.pi)*torch.acos(loss)
    loss_angle = loss_angle[torch.nonzero(mask_t)] 

    mean = torch.mean(loss_angle)
    median = torch.median(loss_angle)
    val_num = loss_angle.size(0)
    small = torch.sum(torch.lt(loss_angle, 11.25)).to(torch.float)/val_num
    mid = torch.sum(torch.lt(loss_angle, 22.5)).to(torch.float)/val_num
    large = torch.sum(torch.lt(loss_angle, 30)).to(torch.float)/val_num

    outputs_n = 0.5*(input_v+1)                
    outputs_n = outputs_n.view(-1, h, w, ch)# bs*h*w*3

    return outputs_n, mean.data.item(), median.data.item(), small.data.item(), mid.data.item(), large.data.item()

