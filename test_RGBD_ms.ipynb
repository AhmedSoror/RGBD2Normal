{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os\n",
    "import torch\n",
    "import argparse\n",
    "import timeit\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from os.path import join as pjoin\n",
    "import scipy.io as io\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import get_model, get_lossfun\n",
    "from loader import get_data_path, get_loader\n",
    "from pre_trained import get_premodel\n",
    "from utils import norm_imsave, change_channel\n",
    "from models.eval import eval_normal_pixel, eval_print\n",
    "from loader.loader_utils import png_reader_32bit, png_reader_uint8\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "def test(args):\n",
    "    # Setup Model\n",
    "    # Setup the fusion model (RGB+Depth)\n",
    "    model_name_F = args.arch_F\n",
    "    model_F = get_model(model_name_F, True)  # concat and output\n",
    "    model_F = torch.nn.DataParallel(model_F, device_ids=range(torch.cuda.device_count()))\n",
    "    # Setup the map model\n",
    "    if args.arch_map == 'map_conv':\n",
    "        model_name_map = args.arch_map\n",
    "        model_map = get_model(model_name_map, True)  # concat and output\n",
    "        model_map = torch.nn.DataParallel(model_map, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "    if args.model_full_name != '':\n",
    "        # Use the full name of model to load\n",
    "        print(\"Load training model: \" + args.model_full_name)\n",
    "        checkpoint = torch.load(pjoin(args.model_savepath, args.model_full_name))\n",
    "        model_F.load_state_dict(checkpoint['model_F_state'])\n",
    "        model_map.load_state_dict(checkpoint[\"model_map_state\"])\n",
    "\n",
    "\n",
    "    # Setup image\n",
    "    if args.imgset:\n",
    "        print(\"Test on dataset: {}\".format(args.dataset))\n",
    "        data_loader = get_loader(args.dataset)\n",
    "        data_path = get_data_path(args.dataset)\n",
    "        v_loader = data_loader(data_path, split=args.test_split, img_size=(args.img_rows, args.img_cols),\n",
    "                               img_norm=args.img_norm)\n",
    "        evalloader = data.DataLoader(v_loader, batch_size=1)\n",
    "        print(\"Finish Loader Setup\")\n",
    "\n",
    "        model_F.cuda()\n",
    "        model_F.eval()\n",
    "        if args.arch_map == 'map_conv':\n",
    "            model_map.cuda()\n",
    "            model_map.eval()\n",
    "\n",
    "        sum_mean, sum_median, sum_small, sum_mid, sum_large, sum_num = [], [], [], [], [], []\n",
    "        evalcount = 0\n",
    "        with torch.no_grad():\n",
    "            for i_val, (images_val, labels_val, masks_val, valids_val, depthes_val, meshdepthes_val) in tqdm(\n",
    "                    enumerate(evalloader)):\n",
    "\n",
    "                images_val = Variable(images_val.contiguous().cuda())\n",
    "                labels_val = Variable(labels_val.contiguous().cuda())\n",
    "                masks_val = Variable(masks_val.contiguous().cuda())\n",
    "                valids_val = Variable(valids_val.contiguous().cuda())\n",
    "                depthes_val = Variable(depthes_val.contiguous().cuda())\n",
    "\n",
    "                if args.arch_map == 'map_conv':\n",
    "                    outputs_valid = model_map(torch.cat((depthes_val, valids_val[:, np.newaxis, :, :]), dim=1))\n",
    "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images_val, depthes_val,\n",
    "                                                                              outputs_valid.squeeze(1))\n",
    "                else:\n",
    "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images_val, depthes_val, valids_val)\n",
    "\n",
    "                outputs_n, pixelnum, mean_i, median_i, small_i, mid_i, large_i = eval_normal_pixel(outputs, labels_val,\n",
    "                                                                                                   masks_val)\n",
    "                outputs_norm = np.squeeze(outputs_n.data.cpu().numpy(), axis=0)\n",
    "                labels_val_norm = np.squeeze(labels_val.data.cpu().numpy(), axis=0)\n",
    "                images_val = np.squeeze(images_val.data.cpu().numpy(), axis=0)\n",
    "                images_val = images_val + 0.5\n",
    "                images_val = images_val.transpose(1, 2, 0)\n",
    "                depthes_val = np.squeeze(depthes_val.data.cpu().numpy(), axis=0)\n",
    "                depthes_val = np.transpose(depthes_val, [1, 2, 0])\n",
    "                depthes_val = np.repeat(depthes_val, 3, axis=2)\n",
    "\n",
    "                outputs_norm = change_channel(outputs_norm)\n",
    "                labels_val_norm = (labels_val_norm + 1) / 2\n",
    "                labels_val_norm = change_channel(labels_val_norm)\n",
    "\n",
    "                # if (i_val+1)%10 == 0:\n",
    "                misc.imsave(pjoin(args.testset_out_path, \"{}_MS_hyb.png\".format(i_val + 1)), outputs_norm)\n",
    "                misc.imsave(pjoin(args.testset_out_path, \"{}_gt.png\".format(i_val + 1)), labels_val_norm)\n",
    "                misc.imsave(pjoin(args.testset_out_path, \"{}_in.jpg\".format(i_val + 1)), images_val)\n",
    "                misc.imsave(pjoin(args.testset_out_path, \"{}_depth.png\".format(i_val + 1)), depthes_val)\n",
    "\n",
    "                # accumulate the metrics in matrix\n",
    "                if ((np.isnan(mean_i)) | (np.isinf(mean_i)) == False):\n",
    "                    sum_mean.append(mean_i)\n",
    "                    sum_median.append(median_i)\n",
    "                    sum_small.append(small_i)\n",
    "                    sum_mid.append(mid_i)\n",
    "                    sum_large.append(large_i)\n",
    "                    sum_num.append(pixelnum)\n",
    "                    evalcount += 1\n",
    "                    if (i_val + 1) % 10 == 0:\n",
    "                        print(\"Iteration %d Evaluation Loss: mean %.4f, median %.4f, 11.25 %.4f, 22.5 %.4f, 30 %.4f\" % (\n",
    "                            i_val + 1,\n",
    "                            mean_i, median_i, small_i, mid_i, large_i))\n",
    "\n",
    "                        # Summarize the result\n",
    "            eval_print(sum_mean, sum_median, sum_small, sum_mid, sum_large, sum_num, item='Pixel-Level')\n",
    "\n",
    "            avg_mean = sum(sum_mean) / evalcount\n",
    "            sum_mean.append(avg_mean)\n",
    "            avg_median = sum(sum_median) / evalcount\n",
    "            sum_median.append(avg_median)\n",
    "            avg_small = sum(sum_small) / evalcount\n",
    "            sum_small.append(avg_small)\n",
    "            avg_mid = sum(sum_mid) / evalcount\n",
    "            sum_mid.append(avg_mid)\n",
    "            avg_large = sum(sum_large) / evalcount\n",
    "            sum_large.append(avg_large)\n",
    "            print(\n",
    "                    \"evalnum is %d, Evaluation Image-Level Mean Loss: mean %.4f, median %.4f, 11.25 %.4f, 22.5 %.4f, 30 %.4f\" % (\n",
    "                evalcount,\n",
    "                avg_mean, avg_median, avg_small, avg_mid, avg_large))\n",
    "\n",
    "            sum_matrix = np.transpose([sum_mean, sum_median, sum_small, sum_mid, sum_large])\n",
    "            if args.model_full_name != '':\n",
    "                sum_file = args.model_full_name[:-4] + '.csv'\n",
    "\n",
    "            np.savetxt(pjoin(args.model_savepath, sum_file), sum_matrix, fmt='%.6f', delimiter=',')\n",
    "            print(\"Saving to %s\" % (sum_file))\n",
    "            # end of dataset test\n",
    "    else:\n",
    "        # if os.path.isdir(args.out_path) == False:\n",
    "        #     os.mkdir(args.out_path)\n",
    "        print(\"Read Input Image from : {}\".format(args.img_path))\n",
    "        for i in os.listdir(args.img_path):\n",
    "            if not i.endswith('.jpg'):\n",
    "                continue\n",
    "\n",
    "            print i\n",
    "            input_f = args.img_path + i\n",
    "            depth_f = args.depth_path + i[:-4] + '.png'\n",
    "            output_f = args.out_path + i[:-4] + '_rgbd.png'\n",
    "            img = misc.imread(input_f)\n",
    "            print('test_L160_ RGB--------------',img.shape)\n",
    "            \n",
    "            img_d = misc.imread(depth_f)\n",
    "            print('test_L163_ depth--------------',img_d.shape)\n",
    "\n",
    "            orig_size = img.shape[:-1]\n",
    "            if args.img_rot:\n",
    "                img = np.transpose(img, (1, 0, 2))\n",
    "                img = np.flipud(img)\n",
    "                img = misc.imresize(img, (args.img_cols, args.img_rows))  # Need resize the image to model inputsize\n",
    "            else:\n",
    "                img = misc.imresize(img, (args.img_rows, args.img_cols))  # Need resize the image to model inputsize\n",
    "\n",
    "            img = img.astype(np.float)\n",
    "            if args.img_norm:\n",
    "                img = (img - 128) / 255\n",
    "            # NHWC -> NCHW\n",
    "            img = img.transpose(2, 0, 1)\n",
    "            img = np.expand_dims(img, 0)\n",
    "            img = torch.from_numpy(img).float()\n",
    "\n",
    "            if args.img_rot:\n",
    "                # depth = png_reader_32bit(depth_f, (args.img_rows, args.img_cols))\n",
    "                depth = png_reader_32bit(depth_f)\n",
    "                depth = np.transpose(depth, (1, 0))\n",
    "                depth = np.flipud(depth)\n",
    "                # valid = png_reader_uint8(mask_f, (args.img_rows,args.img_cols))\n",
    "                # valid = np.transpose(valid, (1,0))\n",
    "                # valid = np.flipud(valid)\n",
    "            else:\n",
    "                depth = png_reader_32bit(depth_f, (args.img_rows, args.img_cols))\n",
    "                # valid = png_reader_uint8(mask_f, (args.img_rows,args.img_cols))\n",
    "\n",
    "            depth = depth.astype(float)\n",
    "            # Please change to the scale so that scaled_depth=1 corresponding to real 10m depth\n",
    "            # matterpot depth=depth/40000  scannet depth=depth/10000\n",
    "            depth = depth / (args.d_scale)\n",
    "            if depth.ndim == 3:  # to dim 2\n",
    "                depth = depth[:, :, 0]\n",
    "                # if valid.ndim == 3: #to dim 2\n",
    "            #     valid = valid[:,:,0]\n",
    "\n",
    "            # valid = 1-depth\n",
    "            # valid[valid>1] = 1\n",
    "            valid = (depth > 0.0001).astype(float)\n",
    "            # valid = depth.astype(float)\n",
    "            depth = depth[np.newaxis, :, :]\n",
    "            depth = np.expand_dims(depth, 0)\n",
    "            valid = np.expand_dims(valid, 0)\n",
    "            depth = torch.from_numpy(depth).float()\n",
    "            valid = torch.from_numpy(valid).float()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                model_F.cuda()\n",
    "                model_F.eval()\n",
    "                if args.arch_map == 'map_conv':\n",
    "                    model_map.cuda()\n",
    "                    model_map.eval()\n",
    "                images = Variable(img.contiguous().cuda())\n",
    "                depth = Variable(depth.contiguous().cuda())\n",
    "                valid = Variable(valid.contiguous().cuda())\n",
    "            else:\n",
    "                images = Variable(img)\n",
    "                depth = Variable(depth)\n",
    "                valid = Variable(valid)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if args.arch_map == 'map_conv':\n",
    "                    outputs_valid = model_map(torch.cat((depth, valid[:, np.newaxis, :, :]), dim=1))\n",
    "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images, depth,\n",
    "                                                                              outputs_valid.squeeze(1))\n",
    "                else:\n",
    "                    outputs, outputs1, outputs2, outputs3, output_d = model_F(images, depth, outputs_valid)\n",
    "\n",
    "            outputs_norm = norm_imsave(outputs)\n",
    "            outputs_norm = np.squeeze(outputs_norm.data.cpu().numpy(), axis=0)\n",
    "            # outputs_norm = misc.imresize(outputs_norm, orig_size)\n",
    "            outputs_norm = change_channel(outputs_norm)\n",
    "        \n",
    "            misc.imsave(\"result/\"+i+\".png\", outputs_norm[0])\n",
    "        print(\"Complete\")\n",
    "        # end of test on no dataset images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Load training model: fconv_ms_scannet_l1_1_hybrid_best.pkl\nRead Input Image from : ./sample_pic/sc_rgb/\n32.jpg\n('test_L160_ RGB--------------', (968, 1296, 3))\n('test_L163_ depth--------------', (480, 640))\n/home/ahmed/.local/lib/python2.7/site-packages/ipykernel_launcher.py:154: DeprecationWarning: `imread` is deprecated!\n`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imread`` instead.\n/home/ahmed/.local/lib/python2.7/site-packages/ipykernel_launcher.py:157: DeprecationWarning: `imread` is deprecated!\n`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imread`` instead.\n/home/ahmed/.local/lib/python2.7/site-packages/ipykernel_launcher.py:166: DeprecationWarning: `imresize` is deprecated!\n`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\nUse Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\nComplete\n/home/ahmed/.local/lib/python2.7/site-packages/ipykernel_launcher.py:234: DeprecationWarning: `imsave` is deprecated!\n`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imwrite`` instead.\n"
    }
   ],
   "source": [
    "parser = namedtuple(\"Parser\",\"arch_RGB arch_D arch_map arch_F model_savepath model_full_name dataset test_split \\\n",
    "        loss model_num img_rows img_cols imgset testset_out_path img_path depth_path ir_path out_path d_scale img_norm img_rot\")\n",
    "args = parser( 'vgg_16_in', 'unet_3_mask_in' , 'map_conv', 'fconv_ms', './checkpoint/FCONV_MS/', 'fconv_ms_scannet_l1_1_hybrid_best.pkl', 'matterport', '','l1', '2'\n",
    "    , 480, 640,False, './result/mt_clean_small', './sample_pic/sc_rgb/', './sample_pic/sc_depth/' , '../Depth2Normal/Dataset/ir_mask/', './result/demo_rgbd_sc/'\n",
    "    , 10000,True, False)\n",
    "    \n",
    "test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python271764bit6969c65f974248059fbdea9e3d1baa29",
   "display_name": "Python 2.7.17 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}